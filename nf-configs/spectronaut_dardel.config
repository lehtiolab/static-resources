external_config_version = 'main'

includeConfig "https://raw.githubusercontent.com/lehtiolab/static-resources/${external_config_version}/nf-configs/pdc_dardel.config"

def listify(it) {
  /* This function is useful when needing a list even when having a single item
  - Single items in channels get unpacked from a list
  - Processes expect lists. Even though it would be fine
  without a list, for single-item-lists any special characters are not escaped by NF
  in the script, which leads to errors. See:
  https://github.com/nextflow-io/nextflow/discussions/4240
  */
  return it instanceof java.util.List ? it : [it]
}


// 10 nodes from shared partition, 10 from main, 5 from memory partition
nodelist = [
  // shared partition for jobs < 111GB (smaller batches < 10 fns)
  'nid002568', 'nid002569', 'nid002570', 'nid002571', 'nid002572', 'nid002573', 'nid002574', 'nid002575', 'nid002576', 'nid002577', 

  // main partition for jobs > 111GB
  'nid002762', 'nid002763', 'nid002764', 'nid002765', 'nid002766', 'nid002767', 'nid002768', 'nid002769', 'nid002770', 'nid002771', 

  // memory partition for jobs > 222GB
  'nid002563', 'nid002564', 'nid002565', 'nid002566', 'nid002567',
]

params.nodelist = nodelist = nodelist.join(',')
params.clusterOptions = "-N 1 --nodelist=${params.nodelist}"
params.cachedir = '/cfs/klemming/projects/supr/snic2019-35-26/kantele_runs/nf_workdir/__spectronaut_cache'

// Always overbook half a node with cpus=130,
// so we cannot run multiple processes on a single node.
// This is done because that is incompatible with license, program will crash
// memory may need some trying and tuning, depend on file size, batch size? 
process {
  withName: generateLibrary {
    cpus = 130
    memory = {listify(raws).size() > 10 ? 128.GB + 2.GB * raws.size() * task.attempt : 128.GB * task.attempt}
    time = {listify(raws).size() > 3 ? 1.h * raws.size() * task.attempt : 2.h * task.attempt}
  }

  withName: mergePsar {
   // depend on size but 30 libraries TIMS data took only 60GB
    cpus = 130
    memory = 230.GB
  }

  withName: searchDIA {
    cpus = 130
    memory = {listify(raws).size() > 10 ? 128.GB + 2.GB * raws.size() * task.attempt : 100.GB * task.attempt }
    time = {listify(raws).size() > 4 ? 0.25.h * raws.size() * task.attempt : 2.h * task.attempt}
  }

  withName: mergeSNE {
    cpus = 130
    memory = 230.GB
  }

  withName: quantReport {
    cpus = 130
    memory = 230.GB
  }
}

workflow {
  output {
    mode = 'copy'
  }
}
